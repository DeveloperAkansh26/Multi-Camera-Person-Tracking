import cv2
import numpy as np
from ultralytics import YOLO
import pandas as pd
import torch
import timm
import torch.nn.functional as F
from torch import nn
from torch.utils.data import Dataset, DataLoader
from skimage import io
from sklearn.model_selection import train_test_split
from tqdm import tqdm
import csv


DATA_DIR = "/home/akansh_26/Hackathons/VisionX-AI/Person-Re-Id-Dataset/train"
DEVICE = "cuda"

MAIN_ENCODING = None
count = 0
URL1 = "/home/akansh_26/Hackathons/VisionX-AI/CV Test Dataset/test_case_2/frame_6.mp4"
URL2 = "/home/akansh_26/Hackathons/VisionX-AI/CV Test Dataset/test_case_2/frame_2.mp4"
URL3 = "/home/akansh_26/Hackathons/VisionX-AI/CV Test Dataset/test_case_2/frame_4.mp4"


model_yolo1 = YOLO("yolo11s.pt")
cam1 = cv2.VideoCapture(URL1)

model_yolo2 = YOLO("yolo11s.pt")
cam2 = cv2.VideoCapture(URL2)
cam3 = cv2.VideoCapture(URL3)


def main():
    while True:
        ret1, frame1 = cam1.read()
        ret2, frame2 = cam2.read()
        ret3, frame3 = cam3.read()

        for i in range(2):
            ret1, frame1 = cam1.read()
            ret2, frame2 = cam2.read()
            ret3, frame3 = cam3.read()

        if not ret1 or not ret2:
            break

        annotated_frame1 = process_frame(frame1, model_yolo1, 1)
        annotated_frame2 = process_frame(frame2, model_yolo2, 2)
        annotated_frame3 = process_frame(frame3, model_yolo2, 3)

        cv2.imshow("frame1", cv2.resize(annotated_frame1, (640, 320)))
        cv2.imshow("frame2", cv2.resize(annotated_frame2, (640, 320)))
        cv2.imshow("frame3", cv2.resize(annotated_frame3, (640, 320)))


        cv2.waitKey(1)
    cv2.destroyAllWindows()


def process_frame(frame, model_yolo, camera_number):
    global count
    global MAIN_ENCODING

    distF = 1000000
    distB = 1000000

    results = model_yolo(frame, verbose=False)
    distances_across = []
    bounding_boxes_list = []

    for result in results:
        for box, cls, conf in zip(result.boxes.xyxy, result.boxes.cls, result.boxes.conf):
            if cls != 0:
                continue
            
            count += 1

            x1, y1, x2, y2 = box
            pt1 = (int(x1), int(y1))
            pt2 = (int(x2), int(y2))

            if MAIN_ENCODING is not None and MAIN_ENCODING.any():
                img_person = frame[int(y1):int(y2), int(x1):int(x2)]
                img_person = cv2.resize(img_person, (128, 64))
                img_person = torch.from_numpy(img_person).permute(2, 0, 1) / 255.0
                model_siamese.eval()
                with torch.no_grad():
                    img_person = img_person.to(DEVICE)
                    person_enc = model_siamese(img_person.unsqueeze(0))
                    person_enc = person_enc.detach().cpu().numpy()


                distance = []
                for i in MAIN_ENCODING:
                    dist = euclidean_dist(i, person_enc)
                    distance.append(dist)
                
                print(distance)
                dist = min(distance)

                threshold = 3
                if dist < threshold:
                    distances_across.append(dist)
                    bounding_boxes_list.append(box)

    if len(distances_across) == 1:
        x1, y1, x2, y2 = bounding_boxes_list[0]
        pt1 = (int(x1), int(y1))
        pt2 = (int(x2), int(y2))
        cv2.rectangle(frame, pt1, pt2, color=(0, 255, 0), thickness=2)
        cv2.putText(frame, f"ID:{1}", (int(x1), int(y1)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
    else:
        try:
            idx = np.argmin(distances_across)
            x1, y1, x2, y2 = bounding_boxes_list[idx]
            pt1 = (int(x1), int(y1))
            pt2 = (int(x2), int(y2))
            cv2.rectangle(frame, pt1, pt2, color=(0, 255, 0), thickness=2)
            cv2.putText(frame, f"ID:{1}", (int(x1), int(y1)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
        except:
            pass

    return frame


class APN_Model(nn.Module):

    def __init__(self, emb_size=512):
        super(APN_Model, self).__init__()

        self.efficientnet = timm.create_model('efficientnet_b0', pretrained=True)
        self.efficientnet.classifier = nn.Linear(in_features=self.efficientnet.classifier.in_features, out_features=emb_size)

    def forward(self, images):

        embeddings = self.efficientnet(images)
        return embeddings


model_siamese = APN_Model()
model_siamese.to(DEVICE)
model_siamese.load_state_dict(torch.load("best_model.pt"))


def get_input():
    global user_input
    user_input = input("Enter a number: ")

def euclidean_dist(enc1, enc2):
    dist = np.sqrt(np.dot(enc1 - enc2, (enc1 - enc2).T))
    return dist


MAIN_ENCODING = np.array([[-0.095656276,0.01345613,-0.21676901,0.2604756,0.27031794,-0.030303089,0.3100235,0.15917987,-0.2766291,-0.14208964,1.2106012,0.16859098,-0.032314956,-0.032332685,0.5686065,-0.24439944,-0.30587053,-0.41064292,0.07153033,-0.20495884,0.3917855,0.56199396,-0.6032264,0.20907673,0.31396893,-0.1814434,-0.41531023,0.10129464,-1.1290865,0.19463465,-0.7794181,0.38084805,-0.40163362,-0.37395576,0.27851698,-0.35503855,0.4513281,0.14808172,0.5234309,0.103551,-0.12608968,0.15737237,0.16878983,-0.3398619,-0.40834078,-0.7291789,0.5555798,0.3731927,0.7649026,0.43261343,-0.5035244,-0.5302084,-0.12005886,-0.6516358,-0.07852547,-0.2748349,-0.19872393,0.9987305,0.44124094,0.38644078,0.0034907684,0.32452062,-0.06660877,-0.36186704,0.158611,0.18369207,-0.21312687,-0.13470817,0.07898113,0.22220998,0.19137467,0.6847857,-0.55852276,-0.56280124,0.123148024,0.71417665,0.09333164,0.48673227,0.031155871,0.69401115,0.3531349,0.2710671,0.16801536,0.067418076,-0.69161963,-0.2724549,-0.08213485,0.015012213,0.26252326,0.5473502,-0.053657636,-0.22011128,-0.24870178,0.069878586,-0.22660193,-0.033928342,0.11460111,-0.059721638,0.15798219,0.36936292,0.16559464,0.112228364,-0.10981217,0.3096759,-0.43178457,0.47123796,0.6365371,0.4699533,0.4007727,-0.6256023,0.42064887,0.096037425,0.09319344,-0.075914755,0.6795553,-0.7172147,-0.16519439,0.48611483,0.07586797,0.3986104,0.6077991,-0.29458067,0.06877219,-0.1593981,-0.44837466,-0.35410154,0.2202384,0.0353171,0.03850183,-0.3217535,0.5144575,0.19973126,-0.23273368,0.25198087,0.69548535,0.047906756,-0.080588825,0.10113756,0.19641805,0.89137655,-0.18677144,-0.14437759,-0.15086985,-0.2780609,0.022008903,0.082515955,0.088735126,0.039143413,0.068350345,-0.39452192,0.24389206,0.7324859,0.30154145,0.95346665,0.22746943,0.18613788,-1.020304,-0.32192266,0.40290245,-0.09002512,0.650433,0.16350703,0.12315711,0.39969134,-0.124249734,-0.065273754,-0.53725404,0.37795064,-0.0082260985,-0.002894193,-0.25458714,-0.6160139,0.7536946,-0.14815459,-0.07675174,-0.024704175,-0.14793348,-0.059648737,-0.19307406,-0.17258297,1.2610071,-0.08470997,-0.09728073,-0.43469653,-0.0945918,-0.29078156,-0.4833677,-0.30405462,0.32037136,-0.1480917,-0.0033383097,0.5291123,-0.31415382,0.246574,0.57860434,0.72186124,-0.030538078,0.52022785,0.18551973,-0.5306613,-0.09085316,-0.65056545,0.10596047,0.21800348,-0.3222459,0.52865916,0.23267424,-0.37368637,-0.56306237,0.13326608,0.041486748,-0.11838815,-0.4263301,-0.342558,0.41871783,0.10569702,0.51619697,-0.23981132,0.44464287,-0.40125918,-0.10905813,0.3078834,0.31066963,-0.01148711,-0.59936225,-0.045135096,0.019320998,0.82751137,-0.51592284,-0.5486905,-0.17608027,-0.52370906,0.056824796,-0.17938529,0.20413645,-0.24956414,0.23375146,-0.5500042,0.025325827,-0.023159372,0.31455135,0.16875398,-0.6708299,-0.4352844,0.15394339,-0.6127212,-0.19913484,0.18454324,-0.01208386,0.09907991,0.25265896,0.06529297,-0.28780723,0.43402097,0.03583327,0.3082384,-0.25887176,0.053344384,0.34951726,-0.36471397,0.09567341,-0.15294749,-0.4141345,-0.35966846,0.0065298807,-0.57319105,0.55512315,0.6216789,-0.1649465,0.5580318,0.019528907,0.44638702,0.19504005,0.13000731,-0.2213688,-0.30418038,0.16844982,-0.20029418,-0.3255918,0.23070522,-0.4722286,0.11815846,0.26287797,0.21744719,-0.0664672,-0.27625933,0.013210349,-0.2363995,0.7845931,-0.36994866,-0.7342576,-0.1814262,0.23914728,0.004210513,-0.37710398,0.48908517,-0.025277551,0.27618515,-0.004212085,-0.3698652,0.08231092,0.32152387,-0.5607587,-0.47003525,0.45488527,0.0064616655,0.142154,0.16100834,-0.25795922,0.09631929,-0.6655841,-0.67963046,0.13180093,0.2591471,-0.60103583,0.17424403,-0.22640891,0.38341948,0.41416073,0.35072264,0.032524537,0.41394174,0.6576378,0.52080935,0.044018164,-0.15221311,0.17006598,0.3759861,0.29674536,0.07115812,0.64852923,-0.37974378,0.6549804,0.07511317,-0.07375535,0.15127379,0.114168435,0.18945459,0.23799554,-0.35143232,0.07482263,0.34602335,0.31795985,0.5482426,-0.83511573,0.40430135,-0.28927982,-0.03849975,0.27202517,0.112275645,-0.6229799,0.089072675,-0.92369545,0.16775745,-0.3636229,-0.8221696,-0.15339777,-0.019626537,0.5139853,-0.762046,0.2855624,0.7767792,0.27915636,0.73268694,-0.11307334,-0.51101464,-0.49059588,-0.47190747,-0.25445905,0.6761762,0.80387187,0.33361554,-0.1924402,0.020138778,-0.18374577,0.42236432,0.46073943,0.24823897,-0.7173532,0.25680166,0.18841922,-0.24289347,-0.566937,0.046277903,0.13964343,-0.047933657,-0.23120917,-0.23246749,0.06208342,-0.687769,0.36553526,-0.6110933,0.35236663,-0.43386075,-0.2570967,-0.59417135,0.050536476,0.016351713,0.1250737,-0.5250173,-0.1339332,0.39314422,0.32982022,0.34713352,0.12064397,-0.08090302,0.30602148,0.28373477,0.17855798,-0.26734507,-0.5535554,-0.6966729,0.27422413,-0.49444285,0.68345505,-0.07141194,-0.34220126,0.06804595,-0.3573925,-0.32139954,0.08363271,-0.19444774,0.5354897,-0.22667234,0.35157666,-0.45465145,-0.11748394,-0.120653845,-0.32824573,-0.05208744,-0.18992582,0.0038401447,-0.75839525,0.41472286,0.14764372,-0.3451703,0.31070787,0.2881951,-0.2174823,0.15235868,-0.3250661,-0.053768136,-0.64478016,0.10109301,-0.017080188,0.79140335,0.77226126,-0.10068707,0.44822457,0.28362313,0.19533697,0.48566127,-0.13813189,-0.49837396,0.53948706,0.07623537,0.10580941,-0.44950047,0.15783219,0.15302113,0.38506225,0.37188628,0.7932706,0.041984268,-0.25461134,-0.30558348,0.5870489,-0.32471126,0.35390124,-0.040562373,-0.23951688,-0.50450283,0.4203081,-0.40928128,-0.55102605,-0.1592547,-0.24056774,0.2469404,-0.34328374,0.08953346,-0.24267592,-0.19477631,0.45101255,-0.26753867,0.30406106,0.09149216,0.24177548,-0.12558748,-0.18092975,0.10874859,-0.0086527,-0.060010634,-0.20295207,-0.6274205,-0.73959225,-0.088835336,-0.34364364,0.51598084,-0.008727146,-0.56156,0.06405304,0.07323481,-0.10019301,0.31411594,0.13379803,0.15223584,-0.40373182,0.030738302,-0.5250665,-0.25925925,0.551669,0.14429253],
                          [-0.30500126,0.16848809,-0.09020207,0.32986262,-0.1016471,-0.092778265,0.2945478,0.242119,-0.21212569,-0.08449866,0.84796786,0.27204287,-0.11685339,0.002875668,0.15303102,-0.09757858,-0.4457807,-0.3606771,-0.0040990487,0.008964404,0.18572582,0.27027583,-0.371702,-0.017538756,0.36268997,-0.19922148,-0.2722591,-0.06274009,-0.77641207,-0.003625827,-0.5273758,0.26255187,-0.2853875,-0.17031859,0.25288954,-0.22235695,0.17065714,0.089159064,0.29884455,-0.018063562,-0.17860423,-0.12311998,-0.013204545,-0.2773338,-0.11700968,-0.57745,0.28171685,0.32326847,0.35747325,0.46077362,-0.36555463,-0.44135317,-0.1398881,-0.38229105,-0.039320868,-0.42969576,-0.07888176,0.7749743,0.48858762,0.21478593,0.06251688,0.32831448,-0.23551457,-0.2583709,0.30542213,0.19084814,-0.08587274,-0.11090218,0.15859187,0.15807511,0.00917992,0.27871877,-0.14293702,-0.4720407,0.22279792,0.19625388,-0.0011954885,0.27704826,-0.038221918,0.5665743,0.4037466,0.09525381,0.07526527,-0.070150174,-0.49963504,-0.27142563,-0.06294205,0.024827985,0.18543571,0.36306167,0.04771156,-0.29378256,-0.18918821,0.20077342,-0.39177516,-0.10062672,-0.023435488,-0.007481318,0.14599513,0.08246604,0.28981122,0.2421336,-0.098956585,0.35211265,-0.25649804,0.29724127,0.34926692,0.49756488,0.32201266,-0.30714178,0.2958731,-0.005747112,0.00044630282,-0.2366314,0.547626,-0.51498663,-0.07165262,0.37125227,0.10100304,0.4557634,0.4590685,-0.2265028,-0.018743617,-0.12739302,-0.30903324,-0.32362962,0.19072337,-0.05940436,0.008058015,-0.20761816,0.2825021,0.04672893,0.07486814,0.24128231,0.48989895,0.121751584,-0.14705609,-0.17598958,0.0009843493,0.5958739,-0.1689449,0.11616477,-0.29383436,-0.051251866,-0.029986309,0.12978232,-0.11871915,0.22159143,0.0022179,-0.28880084,0.023764567,0.63173354,0.3549311,0.6927365,0.27508524,0.009403961,-0.8124101,-0.16183513,0.24723504,-0.18040659,0.5469492,-0.0027259458,0.024905104,0.3479951,0.027909068,-0.062224053,-0.3860007,0.23396373,0.09956851,0.37035787,-0.17796451,-0.33482796,0.43068305,-0.20217264,-0.107682064,0.07444323,-0.2035059,-0.0080617275,-0.13920453,-0.020137582,0.802644,0.15710092,-0.072123736,-0.27547798,-0.019057479,-0.10165913,-0.49770674,-0.19191481,0.23891553,-0.22535484,-0.16753693,0.37193286,-0.1343068,0.102896,0.3290212,0.5664705,-0.11919537,0.29833746,0.14951769,-0.3583916,0.054864865,-0.27317432,-0.0069477484,0.18084782,-0.25044674,0.19110277,0.17122987,-0.34403726,-0.25317582,0.22315775,-0.01741935,-0.003587428,-0.36349422,-0.34678757,0.26870728,0.091389686,0.35775894,-0.07348734,0.26705724,-0.20613371,0.08440693,-0.07004467,-0.002389392,0.104642294,-0.45783848,-0.09125724,-0.13193619,0.57666343,0.057888366,-0.49822462,-0.16111574,-0.35631883,0.19244958,-0.15759704,0.2639401,0.0850869,0.2521422,-0.4702452,0.10596978,-0.11861529,0.05463268,-0.050065093,-0.6784842,-0.29592776,0.088540785,-0.35762316,-0.119397685,0.06855904,-0.11979401,0.20192286,0.15215427,-0.26464406,-0.23961473,0.2708819,0.01693999,-0.013468009,-0.25385013,0.10006628,0.14605474,-0.42393148,-0.030299786,-0.05072866,-0.18634166,-0.1159633,-0.15490504,-0.78871864,0.24340728,0.1690899,-0.0042141303,0.2915424,0.013952305,0.15574113,0.103319615,-0.10151234,-0.14740668,-0.25156525,0.33867872,-0.260012,-0.28868312,0.29694605,-0.5201387,0.010910488,0.028238416,0.16969076,-0.10141093,-0.1704568,0.033924576,-0.22826487,0.49275538,0.022210825,-0.5345955,-0.19060782,0.19096655,-0.07355216,-0.27467605,0.2434471,0.030698944,0.33007777,-0.20990191,-0.25968403,0.1624855,0.08908861,-0.010297148,-0.5453502,0.32360217,-0.073782705,0.3002307,0.05460393,-0.123959385,0.063333206,-0.41695967,-0.5269909,-0.08651172,0.40959713,-0.45178297,0.068864346,-0.09864326,0.21119289,0.25983247,0.2592514,0.124365136,0.18913306,0.6265326,0.44129494,0.019639263,-0.068053365,-0.029592477,0.19502038,0.008573525,0.06328467,0.43874684,-0.4275088,0.27352992,0.007087266,-0.050024286,-0.020264516,0.08266577,0.21555862,0.24146558,-0.27406827,-0.0069739716,0.23498951,0.0067138914,0.32296374,-0.57123214,0.18617359,-0.16675809,0.12670511,0.16023213,-0.037222426,-0.22342148,0.10509561,-0.73406035,0.1074824,-0.27600777,-0.5539943,-0.2126678,-0.1340531,0.30890858,-0.7375038,0.1820974,0.54670507,0.008857712,0.42935854,0.046376716,-0.32719883,-0.35825747,-0.36102304,-0.4510733,0.42949188,0.42856595,0.21539342,-0.086925514,-0.08259412,-0.12070383,0.119349405,0.303762,0.04127258,-0.2448301,-0.06701505,0.120925225,-0.13862608,-0.44209188,0.13381961,0.027303163,-0.020547688,-0.029309137,-0.11242931,-0.05074348,-0.72210205,0.11789038,-0.41121265,0.51661617,-0.13465501,-0.2055679,-0.46329147,0.0751286,0.14993435,-0.028094893,-0.37749544,-0.06874288,0.016755305,0.2269415,0.2292923,0.09088571,-0.18082531,0.22790964,0.17406604,0.2053421,0.0053177048,-0.17193662,-0.36353683,0.0067968033,-0.06698641,0.546702,-0.22980374,-0.19204184,0.014330954,-0.20446287,-0.24729785,0.14026542,-0.15781455,0.3200137,-0.21111651,0.06359489,-0.36829916,-0.19752641,0.20494035,-0.25019383,0.04254883,-0.07617381,0.15317772,-0.58962053,0.11600206,0.13251093,-0.10230829,0.2565454,-0.034276016,0.0047964277,0.1386002,-0.19784528,-0.08963503,-0.19786693,0.16668665,0.17399283,0.6183225,0.49555796,-0.23023136,0.14653385,0.1643871,0.21703853,0.20482115,-0.043616362,-0.44784385,0.5195031,0.053420138,-0.15356638,-0.3088972,0.16809583,0.08754879,0.19254443,0.20575038,0.5593859,0.04488357,-0.13227172,-0.28658128,0.47338855,-0.30550632,0.22017747,-0.1308251,-0.34137112,-0.22478573,0.11658943,-0.12943184,-0.36422098,0.121507645,-0.12139093,0.49935266,-0.26178318,0.04181444,-0.06745291,-0.29405153,0.29942155,-0.21986791,0.13694851,0.020314317,0.24613759,-0.11324785,0.038187623,0.09688222,-0.10419914,0.13283849,-0.36056665,-0.6740076,-0.5596158,-0.3060692,-0.39554155,0.056681275,-0.061541215,-0.15131296,-0.011168579,0.19701722,-0.24482086,-0.00035747234,0.10103367,-0.05269674,-0.13352937,0.048847068,-0.35857013,-0.2611922,0.43707925,0.13295504
]])
# front- back sparsh

if __name__ == "__main__":
    main()
